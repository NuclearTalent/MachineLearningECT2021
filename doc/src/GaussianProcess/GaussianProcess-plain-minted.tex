%%
%% Automatically generated file from DocOnce source
%% (https://github.com/hplgit/doconce/)
%%
%%


%-------------------- begin preamble ----------------------

\documentclass[%
oneside,                 % oneside: electronic viewing, twoside: printing
final,                   % draft: marks overfull hboxes, figures with paths
10pt]{article}

\listfiles               %  print all files needed to compile this document

\usepackage{relsize,makeidx,color,setspace,amsmath,amsfonts,amssymb}
\usepackage[table]{xcolor}
\usepackage{bm,ltablex,microtype}

\usepackage[pdftex]{graphicx}

\usepackage[T1]{fontenc}
%\usepackage[latin1]{inputenc}
\usepackage{ucs}
\usepackage[utf8x]{inputenc}

\usepackage{lmodern}         % Latin Modern fonts derived from Computer Modern

% Hyperlinks in PDF:
\definecolor{linkcolor}{rgb}{0,0,0.4}
\usepackage{hyperref}
\hypersetup{
    breaklinks=true,
    colorlinks=true,
    linkcolor=linkcolor,
    urlcolor=linkcolor,
    citecolor=black,
    filecolor=black,
    %filecolor=blue,
    pdfmenubar=true,
    pdftoolbar=true,
    bookmarksdepth=3   % Uncomment (and tweak) for PDF bookmarks with more levels than the TOC
    }
%\hyperbaseurl{}   % hyperlinks are relative to this root

\setcounter{tocdepth}{2}  % levels in table of contents

% --- fancyhdr package for fancy headers ---
\usepackage{fancyhdr}
\fancyhf{} % sets both header and footer to nothing
\renewcommand{\headrulewidth}{0pt}
\fancyfoot[LE,RO]{\thepage}
% Ensure copyright on titlepage (article style) and chapter pages (book style)
\fancypagestyle{plain}{
  \fancyhf{}
  \fancyfoot[C]{{\footnotesize \copyright\ 1999-2018, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license}}
%  \renewcommand{\footrulewidth}{0mm}
  \renewcommand{\headrulewidth}{0mm}
}
% Ensure copyright on titlepages with \thispagestyle{empty}
\fancypagestyle{empty}{
  \fancyhf{}
  \fancyfoot[C]{{\footnotesize \copyright\ 1999-2018, Morten Hjorth-Jensen. Released under CC Attribution-NonCommercial 4.0 license}}
  \renewcommand{\footrulewidth}{0mm}
  \renewcommand{\headrulewidth}{0mm}
}

\pagestyle{fancy}


% prevent orhpans and widows
\clubpenalty = 10000
\widowpenalty = 10000

% --- end of standard preamble for documents ---


% insert custom LaTeX commands...

\raggedbottom
\makeindex
\usepackage[totoc]{idxlayout}   % for index in the toc
\usepackage[nottoc]{tocbibind}  % for references/bibliography in the toc

%-------------------- end preamble ----------------------

\begin{document}

% matching end for #ifdef PREAMBLE

\newcommand{\exercisesection}[1]{\subsection*{#1}}


% ------------------- main content ----------------------



% ----------------- title -------------------------

\thispagestyle{empty}

\begin{center}
{\LARGE\bf
\begin{spacing}{1.25}
Data Analysis and Machine Learning: Machine learning with Gaussian Processes
\end{spacing}
}
\end{center}

% ----------------- author(s) -------------------------

\begin{center}
{\bf Christian Forss√©n${}^{1}$} \\ [0mm]
\end{center}


\begin{center}
{\bf Morten Hjorth-Jensen${}^{2, 3}$} \\ [0mm]
\end{center}

\begin{center}
% List of all institutions:
\centerline{{\small ${}^1$Department of Physics, Chalmers University of Technology, Sweden}}
\centerline{{\small ${}^2$Department of Physics, University of Oslo}}
\centerline{{\small ${}^3$Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University}}
\end{center}
    
% ----------------- end author(s) -------------------------

% --- begin date ---
\begin{center}
Mar 19, 2018
\end{center}
% --- end date ---

\vspace{1cm}


% !split
\subsection*{What is a Gaussian Process?}

\begin{itemize}
\item We have considered splines and kernel regression methods. These
\end{itemize}

\noindent
require choice of somewhat arbitrary set of knots.

\begin{itemize}
\item Antoher possibility is to setup a prior distribution for the
  regression function using a \emph{Gaussian Process}.

\item This is a very flexible class of models that has distinct computational
  and theoretical advantages. It can be viewed as a potentially
  infinite-dimensional generalization of Gaussian distributions.

\item See the excellent (and free) book \href{{http://www.gaussianprocess.org/gpml/}}{Gaussian Processes for Machine
  Learning} by Carl Edward
  Rasmussen and Christopher K. I. Williams. 
\end{itemize}

\noindent
% !split
\subsection*{Gaussian process regression}

\begin{itemize}
\item Realizations from a Gaussian process correspond to random functions

\item Let us first consider an unknown regression function $\mu(x)$ that
  depends on a single, continuous variable $x$.

\item The Gaussian process is written as $\mu \sim \mathrm{GP}(m,k)$, and
  is parametrized in terms of a mean function $m(x)$ and a covariance
  function $k(x,x')$.

\item The GP prior on $\mu$ describes it as a random function for which
  the values at any set of $N$ prespecified points $\{x_i\}_{i=1}^N$
  are a draw from a $N$-dimensional normal distribution
\end{itemize}

\noindent
$$
  \mu(x_1), \ldots \mu(x_N) \sim \mathrm{N}\left( \left( m(x_1),
  \ldots, m(x_N) \right), K(x_1, \ldots, x_N) \right),
$$
  with mean $m$ and covariance $K$.

% !split
\subsection*{Topics}
\begin{itemize}
\item More matematical details

\item The role of the covariance function (different kernels)

\item multidimensional case

\item examples.
\end{itemize}

\noindent

% ------------------- end of main content ---------------

\end{document}

